{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150, Loss: 1.3847\n",
      "Epoch 10/150, Loss: 1.3532\n",
      "Epoch 20/150, Loss: 1.3023\n",
      "Epoch 30/150, Loss: 1.2131\n",
      "Epoch 40/150, Loss: 1.0724\n",
      "Epoch 50/150, Loss: 0.8731\n",
      "Epoch 60/150, Loss: 0.6358\n",
      "Epoch 70/150, Loss: 0.4090\n",
      "Epoch 80/150, Loss: 0.2402\n",
      "Epoch 90/150, Loss: 0.1375\n",
      "Epoch 100/150, Loss: 0.0809\n",
      "Epoch 110/150, Loss: 0.0512\n",
      "Epoch 120/150, Loss: 0.0349\n",
      "Epoch 130/150, Loss: 0.0252\n",
      "Epoch 140/150, Loss: 0.0190\n",
      "Epoch 150/150, Loss: 0.0148\n",
      "Test accuracy: 0.7500\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Embedding, Dense, GlobalAveragePooling1D, Softmax\n",
    "from tensorflow.keras import Model\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Small synthetic intent classification dataset with training and test split\n",
    "train_data = [\n",
    "    (\"hello there\", \"greeting\"),\n",
    "    (\"hi\", \"greeting\"),\n",
    "    (\"goodbye\", \"goodbye\"),\n",
    "    (\"see you later\", \"goodbye\"),\n",
    "    (\"I want to order pizza\", \"order_food\"),\n",
    "    (\"can I get a burger\", \"order_food\"),\n",
    "    (\"what is the weather\", \"ask_weather\"),\n",
    "    (\"is it raining\", \"ask_weather\"),\n",
    "]\n",
    "\n",
    "test_data = [\n",
    "    (\"hey\", \"greeting\"),                      # unseen phrasing for greeting\n",
    "    (\"bye bye\", \"goodbye\"),                   # unseen phrasing for goodbye\n",
    "    (\"order a sandwich\", \"order_food\"),       # unseen food order phrasing\n",
    "    (\"will it rain today\", \"ask_weather\"),    # unseen question phrasing\n",
    "]\n",
    "\n",
    "# Build vocabulary from training and test datasets\n",
    "texts = [t[0] for t in train_data] + [t[0] for t in test_data]\n",
    "all_words = set(word for sentence in texts for word in sentence.lower().split())\n",
    "word2idx = {w: i + 1 for i, w in enumerate(sorted(all_words))}  # start indexing from 1\n",
    "vocab_size = len(word2idx) + 1  # +1 for padding idx 0\n",
    "\n",
    "# Function to convert sentences to sequences of indices (padded)\n",
    "max_len = 6\n",
    "def text_to_seq(text):\n",
    "    words = text.lower().split()\n",
    "    seq = [word2idx[w] for w in words if w in word2idx]\n",
    "    if len(seq) < max_len:\n",
    "        seq += [0] * (max_len - len(seq))\n",
    "    else:\n",
    "        seq = seq[:max_len]\n",
    "    return seq\n",
    "\n",
    "X_train = np.array([text_to_seq(t[0]) for t in train_data])\n",
    "y_train_text = np.array([t[1] for t in train_data])\n",
    "X_test = np.array([text_to_seq(t[0]) for t in test_data])\n",
    "y_test_text = np.array([t[1] for t in test_data])\n",
    "\n",
    "# Label encode targets\n",
    "label_encoder = LabelEncoder()\n",
    "y_train = label_encoder.fit_transform(y_train_text)\n",
    "y_test = label_encoder.transform(y_test_text)\n",
    "num_classes = len(label_encoder.classes_)\n",
    "\n",
    "# Expert sub-models\n",
    "class Expert(Model):\n",
    "    def __init__(self, d_model, num_classes):\n",
    "        super(Expert, self).__init__()\n",
    "        self.dense1 = Dense(32, activation='relu')\n",
    "        self.dense2 = Dense(num_classes)\n",
    "        \n",
    "    def call(self, x):\n",
    "        x = self.dense1(x)\n",
    "        return self.dense2(x)\n",
    "\n",
    "# Gating network\n",
    "class GatingNetwork(Model):\n",
    "    def __init__(self, d_model, num_experts):\n",
    "        super(GatingNetwork, self).__init__()\n",
    "        self.dense = Dense(num_experts)\n",
    "        self.softmax = Softmax(axis=-1)\n",
    "        \n",
    "    def call(self, x):\n",
    "        logits = self.dense(x)\n",
    "        return self.softmax(logits)\n",
    "\n",
    "# Modify the MoE class call to optionally return gating probabilities\n",
    "class MoEIntentClassifier(Model):\n",
    "    def __init__(self, vocab_size, d_model, num_experts, num_classes):\n",
    "        super(MoEIntentClassifier, self).__init__()\n",
    "        self.embedding = Embedding(vocab_size, d_model, mask_zero=True)\n",
    "        self.pooling = GlobalAveragePooling1D()\n",
    "        self.num_experts = num_experts\n",
    "        self.experts = [Expert(d_model, num_classes) for _ in range(num_experts)]\n",
    "        self.gating_network = GatingNetwork(d_model, num_experts)\n",
    "        \n",
    "    def call(self, x, return_gating=False):\n",
    "        x_emb = self.embedding(x)  # (batch_size, seq_len, d_model)\n",
    "        x_pooled = self.pooling(x_emb)  # (batch_size, d_model)\n",
    "        \n",
    "        gating_probs = self.gating_network(x_pooled)  # (batch_size, num_experts)\n",
    "        expert_outputs = tf.stack([expert(x_pooled) for expert in self.experts], axis=1)  # (batch_size, num_experts, num_classes)\n",
    "        \n",
    "        gated_output = tf.reduce_sum(tf.expand_dims(gating_probs, axis=2) * expert_outputs, axis=1)\n",
    "        if return_gating:\n",
    "            return gated_output, gating_probs\n",
    "        else:\n",
    "            return gated_output\n",
    "\n",
    "# Hyperparameters\n",
    "d_model = 16\n",
    "num_experts = 3\n",
    "epochs = 150\n",
    "batch_size = 4\n",
    "\n",
    "# Prepare datasets\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train)).shuffle(20).batch(batch_size)\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((X_test, y_test)).batch(batch_size)\n",
    "\n",
    "# Instantiate model, loss, optimizer\n",
    "model = MoEIntentClassifier(vocab_size, d_model, num_experts, num_classes)\n",
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(epochs):\n",
    "    total_loss = 0\n",
    "    for x_batch, y_batch in train_dataset:\n",
    "        with tf.GradientTape() as tape:\n",
    "            logits = model(x_batch)\n",
    "            loss = loss_fn(y_batch, logits)\n",
    "        grads = tape.gradient(loss, model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "        total_loss += loss.numpy()\n",
    "    if (epoch + 1) % 10 == 0 or epoch == 0:\n",
    "        print(f\"Epoch {epoch + 1}/{epochs}, Loss: {total_loss/len(train_dataset):.4f}\")\n",
    "\n",
    "# Evaluation on test set\n",
    "correct = 0\n",
    "total = 0\n",
    "for x_batch, y_batch in test_dataset:\n",
    "    logits = model(x_batch)\n",
    "    preds = tf.argmax(logits, axis=1)\n",
    "    correct += tf.reduce_sum(tf.cast(preds == y_batch, tf.int32)).numpy()\n",
    "    total += x_batch.shape[0]\n",
    "print(f\"Test accuracy: {correct/total:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"hello\" -> Predicted intent: greeting, Top Expert used: 2\n",
      "\"hi honey, how are you?\" -> Predicted intent: greeting, Top Expert used: 2\n",
      "\"bye\" -> Predicted intent: greeting, Top Expert used: 1\n",
      "\"see you\" -> Predicted intent: goodbye, Top Expert used: 1\n",
      "\"can I order food\" -> Predicted intent: order_food, Top Expert used: 1\n",
      "\"will it snow tomorrow\" -> Predicted intent: ask_weather, Top Expert used: 0\n",
      "\"is it sunny today\" -> Predicted intent: ask_weather, Top Expert used: 0\n",
      "\"how cloudy is it\" -> Predicted intent: ask_weather, Top Expert used: 0\n",
      "\"how are you\" -> Predicted intent: goodbye, Top Expert used: 1\n",
      "\"I want a pizza\" -> Predicted intent: order_food, Top Expert used: 1\n"
     ]
    }
   ],
   "source": [
    "# Usage for inference with gating info\n",
    "def predict_intent_and_expert(text):\n",
    "    seq = np.array([text_to_seq(text)])\n",
    "    logits, gating_probs = model(seq, return_gating=True)\n",
    "    pred_idx = tf.argmax(logits, axis=1).numpy()[0]\n",
    "    gating_vals = gating_probs.numpy()[0]\n",
    "    predicted_intent = label_encoder.inverse_transform([pred_idx])[0]\n",
    "    # Identify expert with highest gating probability\n",
    "    top_expert = np.argmax(gating_vals)\n",
    "    # Format gating probabilities nicely\n",
    "    gating_str = \", \".join([f\"Expert {i}: {p:.3f}\" for i, p in enumerate(gating_vals)])\n",
    "    return predicted_intent, top_expert, gating_str\n",
    "\n",
    "# Test on unseen phrasing\n",
    "test_phrases = [\n",
    "    \"hello\",\n",
    "    \"hi honey, how are you?\",\n",
    "    \"bye\",\n",
    "    \"see you\",\n",
    "    \"can I order food\",\n",
    "    \"will it snow tomorrow\",\n",
    "    \"is it sunny today\",\n",
    "    \"how cloudy is it\",\n",
    "    \"how are you\",\n",
    "    \"I want a pizza\" \n",
    "]\n",
    "\n",
    "# Example predictions with expert usage\n",
    "for phrase in test_phrases:\n",
    "    intent, expert_used, gating_details = predict_intent_and_expert(phrase)\n",
    "    print(f'\"{phrase}\" -> Predicted intent: {intent}, Top Expert used: {expert_used}')\n",
    "    # print(f'    Gating probabilities: {gating_details}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hcl_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
